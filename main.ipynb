{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f973d61-9cc2-4734-84b2-87552663a205",
   "metadata": {},
   "source": [
    "## Import Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcca468d-34e6-49e8-9d31-cbf5dff4dc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_bag_dataset import FeatureBagDataset\n",
    "from model import Attention_MIL\n",
    "from utility import get_wsi_splits, split_dataset_to_csv\n",
    "from train import train_model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from slide import generate_patch\n",
    "from feature_extractior import FeatureModel, TFRecordProcessor\n",
    "import gc\n",
    "from generate_heatmap import generate_heatmap\n",
    "from utility import get_mpp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ff6904-b289-4407-9f1b-b12a4a35d781",
   "metadata": {},
   "source": [
    "## Generate Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8df7d37b-78d1-4b4c-8e1e-ba15e4e87a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 2923 background tiles for 24-12449-1.\n",
      "Extracted 8850 background tiles for SP-22-05525.\n",
      "Extracted 7590 background tiles for SP-22-05903.\n",
      "Extracted 5201 background tiles for SP-22-05905.\n",
      "Extracted 20173 background tiles for SP-22-06406.\n",
      "Extracted 7585 background tiles for SP-22-06848.\n",
      "Extracted 12140 background tiles for SP-22-06850.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jahid\\anaconda3\\envs\\mrcnn_tf3_8\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\Jahid\\anaconda3\\envs\\mrcnn_tf3_8\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 3464 background tiles for SP-22-07035.\n",
      "Extracted 12750 background tiles for SP-22-07594.\n",
      "Extracted 24572 background tiles for SP-22-07661.\n",
      "Extracted 12933 background tiles for SP-22-07986.\n",
      "Extracted 5366 background tiles for SP-22-08188.\n",
      "Extracted 4783 background tiles for SP-22-08452.\n",
      "Extracted 5239 background tiles for SP-22-08498.\n",
      "Extracted 9811 background tiles for SP-22-08527.\n",
      "Extracted 9989 background tiles for SP-22-08807.\n",
      "Extracted 6026 background tiles for SP-22-08985.\n",
      "Extracted 7545 background tiles for SP-22-09214.\n",
      "Extracted 6480 background tiles for SP22-05522.\n",
      "Extracted 27985 background tiles for SP22-10424.\n",
      "Extracted 18053 background tiles for SP22-11352-B6.\n",
      "Extracted 14080 background tiles for SP22-11352.\n",
      "Extracted 13447 background tiles for SP22-9520.\n",
      "Extracted 13118 background tiles for SP23-2455-1.\n",
      "Extracted 7398 background tiles for SP23-2515-A1.\n",
      "Extracted 11959 background tiles for SP23-2765-1.\n",
      "Extracted 20375 background tiles for SP23-3125-A5.\n",
      "Extracted 9189 background tiles for SP23-3227-A1.\n",
      "Extracted 5972 background tiles for SP23-3395-A1.\n",
      "Extracted 18691 background tiles for SP23-3715-A1.\n",
      "Extracted 22831 background tiles for SP23-3715-B1.\n",
      "Extracted 9752 background tiles for SP23-3715-C1.\n",
      "Extracted 10346 background tiles for SP23-3715-D.\n",
      "Extracted 14624 background tiles for SP23-3875-1.\n",
      "Extracted 10846 background tiles for SP23-3882-A.\n",
      "Extracted 9217 background tiles for SP23-3898-1.\n",
      "Extracted 15678 background tiles for SP23-4018-B3.\n",
      "Extracted 4367 background tiles for SP23-4099-1.\n",
      "Extracted 11423 background tiles for SP23-4153-1.\n",
      "Extracted 32077 background tiles for SP23-4326-A1.\n",
      "Extracted 25944 background tiles for SP23-4359-A1.\n",
      "Extracted 17082 background tiles for SP23-4586-1.\n",
      "Extracted 8092 background tiles for SP23-5211.\n",
      "Extracted 37458 background tiles for SP23-5322-A1.\n",
      "Extracted 10221 background tiles for SP23-5465-1.\n",
      "Extracted 3326 background tiles for SP23-5468A.\n",
      "Extracted 10324 background tiles for SP23-6388A.\n",
      "Extracted 10586 background tiles for SP23-6772-A1.\n",
      "Extracted 6203 background tiles for SP23-6865-1.\n",
      "Extracted 7169 background tiles for SP23-7712-1.\n",
      "Extracted 1483 background tiles for SP23-7785-A1.\n",
      "Extracted 5312 background tiles for SP23-8065-A.\n",
      "Extracted 18367 background tiles for SP23-8367-A2.\n",
      "Extracted 7088 background tiles for SP23-8610A.\n",
      "Extracted 6209 background tiles for SP23-8614-1.\n",
      "Extracted 14432 background tiles for SP23-8875-10.\n",
      "Extracted 5182 background tiles for SP23-9143-1.\n",
      "Extracted 18944 background tiles for SP23-9255.\n",
      "Extracted 8985 background tiles for SP24-1015-A1.\n",
      "Extracted 15716 background tiles for SP24-10723.\n",
      "Extracted 7230 background tiles for SP24-10727-A1.\n",
      "Extracted 17944 background tiles for SP24-10935.\n",
      "Extracted 4822 background tiles for SP24-11134-1.\n",
      "Extracted 4335 background tiles for SP24-11538-A1.\n",
      "Extracted 20712 background tiles for SP24-11630-A2.\n",
      "Extracted 2837 background tiles for SP24-11819.\n",
      "Extracted 6373 background tiles for SP24-11953-A.\n",
      "Extracted 9240 background tiles for SP24-12260.\n",
      "Extracted 20634 background tiles for SP24-1274-B1.\n",
      "Extracted 6595 background tiles for SP24-13117-A1.\n",
      "Extracted 10627 background tiles for SP24-13466.\n",
      "Extracted 23062 background tiles for SP24-1352-A1.\n",
      "Extracted 4171 background tiles for SP24-1359-A1.\n",
      "Extracted 1345 background tiles for SP24-1477.\n",
      "Extracted 4154 background tiles for SP24-1613.\n",
      "Extracted 9424 background tiles for SP24-1672.\n",
      "Extracted 3615 background tiles for SP24-183-A1.\n",
      "Extracted 3566 background tiles for SP24-1845-A1.\n",
      "Extracted 2125 background tiles for SP24-2825-A1.\n",
      "Extracted 15045 background tiles for SP24-374.\n",
      "Extracted 12549 background tiles for SP24-3958-B1.\n",
      "Extracted 35419 background tiles for SP24-4287.\n",
      "Extracted 11601 background tiles for SP24-4399-3.\n",
      "Extracted 9843 background tiles for SP24-4812-D1.\n",
      "Extracted 6426 background tiles for SP24-5473-1.\n",
      "Extracted 14454 background tiles for SP24-5683-B1.\n",
      "Extracted 6507 background tiles for SP24-5685-A1.\n",
      "Extracted 1612 background tiles for SP24-7514-1.\n",
      "Extracted 4686 background tiles for SP24-7828-C1.\n",
      "Extracted 17065 background tiles for SP24-9133.\n",
      "Extracted 17249 background tiles for SP24-9692-1.\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Failed to WriteFile: tfrecode_data\\data1\\SP-22-09444.tfrecord : There is not enough space on the disk.\r\n; operation in progress",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgenerate_patch\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/Users/Jahid/Desktop/Bladder_Data/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtfrecode_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\Vidanex\\vida_multi_class_mil - Bladder_Data\\slide.py:147\u001b[0m, in \u001b[0;36mgenerate_patch\u001b[1;34m(input_dir, output_dir)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    146\u001b[0m processor \u001b[38;5;241m=\u001b[39m SlideProcessor(slide)\n\u001b[1;32m--> 147\u001b[0m num_tiles \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_tiles_and_visualize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mMPP\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_mpp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslide\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_tiles\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m background tiles for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\Vidanex\\vida_multi_class_mil - Bladder_Data\\slide.py:105\u001b[0m, in \u001b[0;36mSlideProcessor.extract_tiles_and_visualize\u001b[1;34m(self, output_dir, image_name, tile_px, tile_um, MPP, im_threshold)\u001b[0m\n\u001b[0;32m    103\u001b[0m tile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslide\u001b[38;5;241m.\u001b[39mread_region((x_start, y_start), \u001b[38;5;241m0\u001b[39m, (actual_tile_size_x, actual_tile_size_y))\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    104\u001b[0m example \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_tfrecord_example(tile, x_start, y_start)\n\u001b[1;32m--> 105\u001b[0m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerializeToString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m vis_x_start, vis_y_start \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(x_start \u001b[38;5;241m*\u001b[39m scale_factor), \u001b[38;5;28mint\u001b[39m(y_start \u001b[38;5;241m*\u001b[39m scale_factor)\n\u001b[0;32m    108\u001b[0m vis_tile_size_x, vis_tile_size_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(actual_tile_size_x \u001b[38;5;241m*\u001b[39m scale_factor), \u001b[38;5;28mint\u001b[39m(actual_tile_size_y \u001b[38;5;241m*\u001b[39m scale_factor)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mrcnn_tf3_8\\lib\\site-packages\\tensorflow\\python\\lib\\io\\tf_record.py:313\u001b[0m, in \u001b[0;36mTFRecordWriter.write\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, record):\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Write a string record to the file.\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \n\u001b[0;32m    310\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;124;03m    record: str\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 313\u001b[0m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTFRecordWriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Failed to WriteFile: tfrecode_data\\data1\\SP-22-09444.tfrecord : There is not enough space on the disk.\r\n; operation in progress"
     ]
    }
   ],
   "source": [
    "generate_patch(input_dir=\"C:/Users/Jahid/Desktop/Bladder_Data/\", output_dir=\"tfrecode_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ce865f-48cf-42cf-b1a1-94c53c7e689f",
   "metadata": {},
   "source": [
    "## Extract Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eb60b3a-aa02-4bf2-a2b9-ce6c52ca1038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = r\"feature_model\\UNI.bin\"\n",
    "\n",
    "# # Initialize the feature model with 'retccl' or 'virchow' or 'uni'\n",
    "# feature_extractor = FeatureModel(model_type=\"virchow\", model_path=model_path, num_classes=2, hf_token=\"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\")\n",
    "# feature_extraction_model = feature_extractor.get_model()\n",
    "# transform = feature_extractor.get_transform()\n",
    "# input_dir = \"tfrecode_data/\"\n",
    "# output_dir=\"extracted_features_virchow\"\n",
    "\n",
    "# processor = TFRecordProcessor(input_dir=input_dir, \n",
    "#                               feature_extraction_model=feature_extraction_model, \n",
    "#                               transform=transform, \n",
    "#                               output_dir=output_dir,\n",
    "#                               model_type=\"virchow\") \n",
    "\n",
    "# processor.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd6b297-4a8b-4f34-a3dc-d86837d7a103",
   "metadata": {},
   "source": [
    "## Split dataset for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee63d250-c447-480c-9a61-23133352e884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_dataset_to_csv(root_dir=\"extracted_features_uni_2_class/\", train_ratio=0.8, output_csv='dataset_split_2_class')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1210f1bb-ebe3-4699-954a-34844257eccf",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0916e8c9-0044-40f9-ab80-fbb667ef9ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class_00', 'class_33', 'class_44', 'class_55']\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "csv_dir = 'dataset_split.csv'\n",
    "root_dir = 'extracted_features_uni_2_class/'\n",
    "bag_size = 64\n",
    "batch_size = 32\n",
    "\n",
    "# Get train/val splits\n",
    "train_files, val_files = get_wsi_splits(csv_dir, root_dir)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = FeatureBagDataset(train_files, bag_size)\n",
    "val_dataset = FeatureBagDataset(val_files, bag_size)\n",
    "print(train_dataset.classes)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbeda27-7451-4f79-a4b1-61782b31fb39",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "804a92bb-9c72-4d3c-9199-14a930da6217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jahid\\anaconda3\\envs\\mrcnn_tf3_8\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/100:  Train Loss: 1.2406 | Acc: 49.22%  Val Loss: 1.2692 | Acc: 63.46%\n",
      "Epoch 002/100:  Train Loss: 0.9832 | Acc: 71.71%  Val Loss: 1.1415 | Acc: 68.27%\n",
      "Epoch 003/100:  Train Loss: 0.8358 | Acc: 78.29%  Val Loss: 0.9928 | Acc: 69.23%\n",
      "Epoch 004/100:  Train Loss: 0.7612 | Acc: 84.50%  Val Loss: 0.8738 | Acc: 72.12%\n",
      "Epoch 005/100:  Train Loss: 0.5347 | Acc: 87.21%  Val Loss: 0.7797 | Acc: 71.15%\n",
      "Epoch 006/100:  Train Loss: 0.4307 | Acc: 89.53%  Val Loss: 0.7115 | Acc: 75.96%\n",
      "Epoch 007/100:  Train Loss: 0.4075 | Acc: 89.53%  Val Loss: 0.6798 | Acc: 75.96%\n",
      "Epoch 008/100:  Train Loss: 0.3905 | Acc: 93.80%  Val Loss: 0.6369 | Acc: 77.88%\n",
      "Epoch 009/100:  Train Loss: 0.2238 | Acc: 95.35%  Val Loss: 0.6278 | Acc: 78.85%\n",
      "Epoch 010/100:  Train Loss: 0.2238 | Acc: 96.12%  Val Loss: 0.6142 | Acc: 79.81%\n",
      "Epoch 011/100:  Train Loss: 0.1634 | Acc: 95.74%  Val Loss: 0.6490 | Acc: 78.85%\n",
      "Epoch 012/100:  Train Loss: 0.1921 | Acc: 96.90%  Val Loss: 0.6370 | Acc: 78.85%\n",
      "Epoch 013/100:  Train Loss: 0.2347 | Acc: 98.06%  Val Loss: 0.6487 | Acc: 77.88%\n",
      "Epoch 014/100:  Train Loss: 0.1642 | Acc: 98.06%  Val Loss: 0.5971 | Acc: 78.85%\n",
      "Epoch 015/100:  Train Loss: 0.0981 | Acc: 99.22%  Val Loss: 0.6005 | Acc: 78.85%\n",
      "Epoch 016/100:  Train Loss: 0.0399 | Acc: 99.61%  Val Loss: 0.5720 | Acc: 80.77%\n",
      "Epoch 017/100:  Train Loss: 0.0325 | Acc: 100.00%  Val Loss: 0.5926 | Acc: 79.81%\n",
      "Epoch 018/100:  Train Loss: 0.2014 | Acc: 99.61%  Val Loss: 0.6303 | Acc: 78.85%\n",
      "Epoch 019/100:  Train Loss: 0.0317 | Acc: 100.00%  Val Loss: 0.6407 | Acc: 76.92%\n",
      "Epoch 020/100:  Train Loss: 0.0125 | Acc: 100.00%  Val Loss: 0.5643 | Acc: 80.77%\n",
      "Epoch 021/100:  Train Loss: 0.2000 | Acc: 99.61%  Val Loss: 0.5999 | Acc: 81.73%\n",
      "Epoch 022/100:  Train Loss: 0.0151 | Acc: 100.00%  Val Loss: 0.6693 | Acc: 76.92%\n",
      "Epoch 023/100:  Train Loss: 0.0703 | Acc: 99.61%  Val Loss: 0.6671 | Acc: 77.88%\n",
      "Epoch 024/100:  Train Loss: 0.4509 | Acc: 99.22%  Val Loss: 0.5830 | Acc: 81.73%\n",
      "Epoch 025/100:  Train Loss: 0.2086 | Acc: 99.61%  Val Loss: 0.6578 | Acc: 78.85%\n",
      "Epoch 026/100:  Train Loss: 0.0232 | Acc: 100.00%  Val Loss: 0.6397 | Acc: 80.77%\n",
      "Epoch 027/100:  Train Loss: 0.1091 | Acc: 99.61%  Val Loss: 0.6682 | Acc: 79.81%\n",
      "Epoch 028/100:  Train Loss: 0.0065 | Acc: 100.00%  Val Loss: 0.6556 | Acc: 79.81%\n",
      "Epoch 029/100:  Train Loss: 0.0112 | Acc: 100.00%  Val Loss: 0.7060 | Acc: 78.85%\n",
      "Epoch 030/100:  Train Loss: 0.0275 | Acc: 100.00%  Val Loss: 0.6779 | Acc: 77.88%\n",
      "Epoch 031/100:  Train Loss: 0.0072 | Acc: 100.00%  Val Loss: 0.7164 | Acc: 76.92%\n",
      "Epoch 032/100:  Train Loss: 0.0058 | Acc: 100.00%  Val Loss: 0.7434 | Acc: 76.92%\n",
      "Epoch 033/100:  Train Loss: 0.0036 | Acc: 100.00%  Val Loss: 0.7591 | Acc: 76.92%\n",
      "Epoch 034/100:  Train Loss: 0.0074 | Acc: 100.00%  Val Loss: 0.7460 | Acc: 78.85%\n",
      "Epoch 035/100:  Train Loss: 0.4632 | Acc: 99.22%  Val Loss: 0.7776 | Acc: 77.88%\n",
      "Epoch 036/100:  Train Loss: 0.0081 | Acc: 100.00%  Val Loss: 0.7091 | Acc: 78.85%\n",
      "Epoch 037/100:  Train Loss: 0.1447 | Acc: 99.61%  Val Loss: 0.6695 | Acc: 77.88%\n",
      "Epoch 038/100:  Train Loss: 0.0074 | Acc: 100.00%  Val Loss: 0.6656 | Acc: 80.77%\n",
      "Epoch 039/100:  Train Loss: 0.0045 | Acc: 100.00%  Val Loss: 0.6945 | Acc: 79.81%\n",
      "Epoch 040/100:  Train Loss: 0.0055 | Acc: 100.00%  Val Loss: 0.7393 | Acc: 77.88%\n",
      "Epoch 041/100:  Train Loss: 0.0071 | Acc: 100.00%  Val Loss: 0.7311 | Acc: 78.85%\n",
      "Epoch 042/100:  Train Loss: 0.0078 | Acc: 100.00%  Val Loss: 0.7449 | Acc: 77.88%\n",
      "Epoch 043/100:  Train Loss: 0.0081 | Acc: 100.00%  Val Loss: 0.6726 | Acc: 81.73%\n",
      "Epoch 044/100:  Train Loss: 0.0254 | Acc: 100.00%  Val Loss: 0.6643 | Acc: 80.77%\n",
      "Epoch 045/100:  Train Loss: 0.0060 | Acc: 100.00%  Val Loss: 0.6740 | Acc: 80.77%\n",
      "Epoch 046/100:  Train Loss: 0.0174 | Acc: 100.00%  Val Loss: 0.6902 | Acc: 81.73%\n",
      "Epoch 047/100:  Train Loss: 0.0216 | Acc: 100.00%  Val Loss: 0.7177 | Acc: 80.77%\n",
      "Epoch 048/100:  Train Loss: 0.0163 | Acc: 100.00%  Val Loss: 0.7226 | Acc: 78.85%\n",
      "Epoch 049/100:  Train Loss: 0.0138 | Acc: 100.00%  Val Loss: 0.7100 | Acc: 78.85%\n",
      "Epoch 050/100:  Train Loss: 0.0060 | Acc: 100.00%  Val Loss: 0.7555 | Acc: 78.85%\n",
      "Epoch 051/100:  Train Loss: 0.0053 | Acc: 100.00%  Val Loss: 0.7072 | Acc: 81.73%\n",
      "Epoch 052/100:  Train Loss: 0.0117 | Acc: 100.00%  Val Loss: 0.7310 | Acc: 78.85%\n",
      "Epoch 053/100:  Train Loss: 0.0029 | Acc: 100.00%  Val Loss: 0.6655 | Acc: 82.69%\n",
      "Epoch 054/100:  Train Loss: 0.0081 | Acc: 100.00%  Val Loss: 0.7328 | Acc: 76.92%\n",
      "Epoch 055/100:  Train Loss: 0.0045 | Acc: 100.00%  Val Loss: 0.7334 | Acc: 77.88%\n",
      "Epoch 056/100:  Train Loss: 0.2749 | Acc: 99.61%  Val Loss: 0.7606 | Acc: 76.92%\n",
      "Epoch 057/100:  Train Loss: 0.2581 | Acc: 99.22%  Val Loss: 0.6659 | Acc: 81.73%\n",
      "Epoch 058/100:  Train Loss: 0.0034 | Acc: 100.00%  Val Loss: 0.6819 | Acc: 80.77%\n",
      "Epoch 059/100:  Train Loss: 0.0043 | Acc: 100.00%  Val Loss: 0.6583 | Acc: 81.73%\n",
      "Epoch 060/100:  Train Loss: 0.0202 | Acc: 100.00%  Val Loss: 0.7320 | Acc: 76.92%\n",
      "Epoch 061/100:  Train Loss: 0.1104 | Acc: 99.61%  Val Loss: 0.7117 | Acc: 77.88%\n",
      "Epoch 062/100:  Train Loss: 0.0081 | Acc: 100.00%  Val Loss: 0.6801 | Acc: 80.77%\n",
      "Epoch 063/100:  Train Loss: 0.0593 | Acc: 99.61%  Val Loss: 0.6733 | Acc: 78.85%\n",
      "Epoch 064/100:  Train Loss: 0.0106 | Acc: 100.00%  Val Loss: 0.7502 | Acc: 77.88%\n",
      "Epoch 065/100:  Train Loss: 0.0022 | Acc: 100.00%  Val Loss: 0.7712 | Acc: 77.88%\n",
      "Epoch 066/100:  Train Loss: 0.0275 | Acc: 100.00%  Val Loss: 0.7734 | Acc: 77.88%\n",
      "Epoch 067/100:  Train Loss: 0.0052 | Acc: 100.00%  Val Loss: 0.7614 | Acc: 78.85%\n",
      "Epoch 068/100:  Train Loss: 0.2068 | Acc: 99.22%  Val Loss: 0.7208 | Acc: 79.81%\n",
      "Epoch 069/100:  Train Loss: 0.0034 | Acc: 100.00%  Val Loss: 0.7147 | Acc: 79.81%\n",
      "Epoch 070/100:  Train Loss: 0.0079 | Acc: 100.00%  Val Loss: 0.6733 | Acc: 82.69%\n",
      "Epoch 071/100:  Train Loss: 0.0100 | Acc: 100.00%  Val Loss: 0.7153 | Acc: 77.88%\n",
      "Epoch 072/100:  Train Loss: 0.0316 | Acc: 100.00%  Val Loss: 0.7480 | Acc: 77.88%\n",
      "Epoch 073/100:  Train Loss: 0.0034 | Acc: 100.00%  Val Loss: 0.7583 | Acc: 77.88%\n",
      "Epoch 074/100:  Train Loss: 0.0483 | Acc: 99.61%  Val Loss: 0.7207 | Acc: 77.88%\n",
      "Epoch 075/100:  Train Loss: 0.0288 | Acc: 100.00%  Val Loss: 0.7311 | Acc: 77.88%\n",
      "Epoch 076/100:  Train Loss: 0.0053 | Acc: 100.00%  Val Loss: 0.7753 | Acc: 78.85%\n",
      "Epoch 077/100:  Train Loss: 0.0885 | Acc: 99.61%  Val Loss: 0.7141 | Acc: 76.92%\n",
      "Epoch 078/100:  Train Loss: 0.0038 | Acc: 100.00%  Val Loss: 0.7701 | Acc: 77.88%\n",
      "Epoch 079/100:  Train Loss: 0.2311 | Acc: 99.61%  Val Loss: 0.7786 | Acc: 77.88%\n",
      "Epoch 080/100:  Train Loss: 0.0661 | Acc: 99.61%  Val Loss: 0.8111 | Acc: 77.88%\n",
      "Epoch 081/100:  Train Loss: 0.2662 | Acc: 99.61%  Val Loss: 0.8021 | Acc: 77.88%\n",
      "Epoch 082/100:  Train Loss: 0.1786 | Acc: 99.61%  Val Loss: 0.6832 | Acc: 80.77%\n",
      "Epoch 083/100:  Train Loss: 0.0297 | Acc: 100.00%  Val Loss: 0.7105 | Acc: 77.88%\n",
      "Epoch 084/100:  Train Loss: 0.0036 | Acc: 100.00%  Val Loss: 0.7307 | Acc: 77.88%\n",
      "Epoch 085/100:  Train Loss: 0.0111 | Acc: 100.00%  Val Loss: 0.7500 | Acc: 77.88%\n",
      "Epoch 086/100:  Train Loss: 0.0132 | Acc: 100.00%  Val Loss: 0.7247 | Acc: 78.85%\n",
      "Epoch 087/100:  Train Loss: 0.0268 | Acc: 100.00%  Val Loss: 0.6901 | Acc: 77.88%\n",
      "Epoch 088/100:  Train Loss: 0.0851 | Acc: 99.61%  Val Loss: 0.6795 | Acc: 76.92%\n",
      "Epoch 089/100:  Train Loss: 0.0675 | Acc: 99.61%  Val Loss: 0.6727 | Acc: 78.85%\n",
      "Epoch 090/100:  Train Loss: 0.0278 | Acc: 100.00%  Val Loss: 0.7243 | Acc: 76.92%\n",
      "Epoch 091/100:  Train Loss: 0.1048 | Acc: 99.22%  Val Loss: 0.7638 | Acc: 76.92%\n",
      "Epoch 092/100:  Train Loss: 0.0047 | Acc: 100.00%  Val Loss: 0.7715 | Acc: 77.88%\n",
      "Epoch 093/100:  Train Loss: 0.2416 | Acc: 99.61%  Val Loss: 0.6543 | Acc: 81.73%\n",
      "Epoch 094/100:  Train Loss: 0.0052 | Acc: 100.00%  Val Loss: 0.7297 | Acc: 76.92%\n",
      "Epoch 095/100:  Train Loss: 0.0084 | Acc: 100.00%  Val Loss: 0.7046 | Acc: 80.77%\n",
      "Epoch 096/100:  Train Loss: 0.0040 | Acc: 100.00%  Val Loss: 0.7336 | Acc: 76.92%\n",
      "Epoch 097/100:  Train Loss: 0.0154 | Acc: 100.00%  Val Loss: 0.6867 | Acc: 78.85%\n",
      "Epoch 098/100:  Train Loss: 0.5585 | Acc: 99.22%  Val Loss: 0.7495 | Acc: 77.88%\n",
      "Epoch 099/100:  Train Loss: 0.0036 | Acc: 100.00%  Val Loss: 0.7297 | Acc: 78.85%\n",
      "Epoch 100/100:  Train Loss: 0.3138 | Acc: 99.22%  Val Loss: 0.6290 | Acc: 80.77%\n",
      "Training complete. Best validation accuracy: 82.69%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "# Get feature dimension\n",
    "sample_bag, _, _ = next(iter(train_loader))\n",
    "n_feats = sample_bag.shape[-1]\n",
    "\n",
    "# Create model\n",
    "model = Attention_MIL(\n",
    "    n_feats=n_feats,\n",
    "    n_out=len(train_dataset.classes),\n",
    "    z_dim=256,\n",
    "    dropout_p=0.5\n",
    ")\n",
    "\n",
    "# Train model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "train_model(model, train_loader, val_loader, num_epochs=num_epochs, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7ee04-dbe6-4565-916a-4e4a89665a0d",
   "metadata": {},
   "source": [
    "## Genarate Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbca845f-0a69-493f-a8e7-f7723a1068da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jahid\\AppData\\Local\\Temp\\ipykernel_18760\\5678460.py:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_polygon_0\\class_55\\0bd231c85b2695e2cf021299e67a6afc.png Predict Class : class_55\n",
      "save_polygon_0\\class_00\\0e65f90aa2b3fd3e49982839aa381583.png Predict Class : class_00\n",
      "save_polygon_0\\class_33\\11fb56dd38d8f4179c702afacbd70d41.png Predict Class : class_33\n",
      "save_polygon_0\\class_44\\158754df49e00760f8e4659a05e7cc0c.png Predict Class : class_44\n",
      "save_polygon_0\\class_44\\1c4653246dc78308252d47160786ad15.png Predict Class : class_44\n",
      "save_polygon_0\\class_33\\29eed8a71c8bee8fc007b0fe4edcc712.png Predict Class : class_33\n",
      "save_polygon_0\\class_00\\29fe9e445bbf0c9d84aec6799cbba4a5.png Predict Class : class_00\n",
      "save_polygon_0\\class_55\\2ca08ec99224f03e8db1f92682ce82d0.png Predict Class : class_55\n",
      "save_polygon_0\\class_55\\3112c494c644128c2a0f7fbc1e9a23f1.png Predict Class : class_55\n",
      "save_polygon_0\\class_33\\3c685ed0f92e30f6ffeb5cea7cef5994.png Predict Class : class_33\n",
      "save_polygon_0\\class_55\\3d3988b1b72273ee018b40c5acd51e43.png Predict Class : class_55\n",
      "save_polygon_0\\class_00\\3d7c76e3d1106d038356561b67b4ac1a.png Predict Class : class_44\n",
      "save_polygon_0\\class_33\\3e16a4a0816d8380163af60dfc884195.png Predict Class : class_33\n",
      "save_polygon_0\\class_44\\4c9cb3b8e0f18845b3911cdc31d6fa94.png Predict Class : class_44\n",
      "save_polygon_0\\class_33\\4e60bebc14d01b30a0873ba7ee026dac.png Predict Class : class_33\n",
      "save_polygon_0\\class_55\\5000f1e3635cd4bf1ac50930e885e935.png Predict Class : class_00\n",
      "save_polygon_0\\class_33\\527d8fc0ea1ef55212f4f2ffd6c4ad68.png Predict Class : class_33\n",
      "save_polygon_0\\class_00\\5477d1fe122c0b899b4be1634d3d8da5.png Predict Class : class_55\n",
      "save_polygon_0\\class_44\\548a1b47c6c3d002e1fab2d2959404db.png Predict Class : class_44\n",
      "save_polygon_0\\class_44\\5f1ccf6d3f6fc9977f54755c8d96784a.png Predict Class : class_44\n",
      "save_polygon_0\\class_55\\625e6a283b25f0a077a714b3adce614c.png Predict Class : class_55\n",
      "save_polygon_0\\class_33\\68d28aa1831633cd996a227062f03bee.png Predict Class : class_33\n",
      "save_polygon_0\\class_44\\6a363e70baf98838b0093f9ae93052fd.png Predict Class : class_44\n",
      "save_polygon_0\\class_55\\6b44920a6758d2dc91635ccb975b3bb7.png Predict Class : class_55\n",
      "save_polygon_0\\class_44\\6bb5a1ea7cae19a7a11fa7cbd55a7410.png Predict Class : class_44\n",
      "save_polygon_0\\class_33\\6cbc6f7259cb45a4086cd584aec53857.png Predict Class : class_33\n",
      "save_polygon_0\\class_00\\77545268b9c0cec2fd73b7cb9e03d66b.png Predict Class : class_00\n",
      "save_polygon_0\\class_00\\7d581d0082d6ee0a32165b0f8fe216d8.png Predict Class : class_00\n",
      "save_polygon_0\\class_00\\7e424dff3f544c36ace6d9219aea34ef.png Predict Class : class_00\n",
      "save_polygon_0\\class_33\\81f1706e615ff80757a041cf70d022f5.png Predict Class : class_33\n",
      "save_polygon_0\\class_33\\821b7c89e5f5879c21cefcdeb0df1657.png Predict Class : class_33\n",
      "save_polygon_0\\class_33\\824dfb4e8eb256cde52493d8667bfe10.png Predict Class : class_33\n",
      "save_polygon_0\\class_55\\8364aaf55439cd2b1207b7bfa35d79a2.png Predict Class : class_55\n",
      "save_polygon_0\\class_00\\864442925e04b7c4018f5c6eeb021212.png Predict Class : class_00\n",
      "save_polygon_0\\class_44\\8d5860e10e09ee25e066ee7fb699453d.png Predict Class : class_44\n",
      "save_polygon_0\\class_33\\963cdce0573b4883f8c416d9808d6e84.png Predict Class : class_33\n",
      "save_polygon_0\\class_44\\9761fb9e15e37b85ea603dbedd0db804.png Predict Class : class_44\n",
      "save_polygon_0\\class_55\\977d38c17c1f872ed1c550c52e984986.png Predict Class : class_55\n",
      "save_polygon_0\\class_44\\9e40b83c6ac2b92e2426b717ed1a200e.png Predict Class : class_44\n",
      "save_polygon_0\\class_44\\a08e24cff451d628df797efc4343e13c.png Predict Class : class_55\n",
      "save_polygon_0\\class_44\\a420d76844dd359a2d3a268be4827768.png Predict Class : class_44\n",
      "save_polygon_0\\class_33\\aa3c01d5326e3ed117d9266d5ed6ef37.png Predict Class : class_33\n",
      "save_polygon_0\\class_33\\ab7f757a2343686945a621a662b6f667.png Predict Class : class_44\n",
      "save_polygon_0\\class_44\\acc092b7ff833d1d9853a2efe449e66e.png Predict Class : class_44\n",
      "save_polygon_0\\class_55\\b768b6c84849f2ba435eae0f5be52c76.png Predict Class : class_00\n",
      "save_polygon_0\\class_55\\bf779325c9c16f04957839ba92518ab8.png Predict Class : class_55\n",
      "save_polygon_0\\class_55\\c2b4cc586b3984b248e7d095d4c0bd03.png Predict Class : class_44\n",
      "save_polygon_0\\class_44\\c614dc18ffa37f8007c2aead39e65342.png Predict Class : class_44\n",
      "save_polygon_0\\class_55\\cb91772271b72c237c42f64fb6d2e84e.png Predict Class : class_55\n",
      "save_polygon_0\\class_33\\d14168b713f3ba30243a69837a001115.png Predict Class : class_33\n",
      "save_polygon_0\\class_44\\dc10032bf598b0a3268074de4bb2d7b6.png Predict Class : class_44\n",
      "save_polygon_0\\class_55\\e0f8b96960ada384a00e493545f783da.png Predict Class : class_55\n",
      "save_polygon_0\\class_33\\e10d5f4e9dd5c9adb81bbe1a744866ec.png Predict Class : class_33\n",
      "save_polygon_0\\class_55\\e19325ebb64adc3293f7173d7a337409.png Predict Class : class_55\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "sample_bag, _, _ = next(iter(val_loader))\n",
    "n_feats = sample_bag.shape[-1]\n",
    "\n",
    "# Load the trained model\n",
    "model = Attention_MIL(\n",
    "    n_feats=n_feats,  # Feature dimension\n",
    "    n_out=len(train_dataset.classes),       # Number of output classes\n",
    "    z_dim=256,\n",
    "    dropout_p=0.5\n",
    ")\n",
    "\n",
    "# Define base paths outside the loop\n",
    "features_base_path = \"extracted_features_uni_2_class\"\n",
    "slides_base_path = \"C:/Users/Jahid/Desktop/WSI_Slideflow/data_4_class\"\n",
    "output_base_path = \"save_polygon_0\"\n",
    "file_path = r'dataset_split.csv'\n",
    "model_path=r\"best_model.pth\"\n",
    "\n",
    "# Load model checkpoint\n",
    "checkpoint = torch.load(model_path, map_location=\"cpu\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "\n",
    "# Filter validation rows\n",
    "validation_rows = df[df['type'] == 'validation']\n",
    "\n",
    "\n",
    "# Iterate through validation rows\n",
    "for index, row in validation_rows.iterrows():\n",
    "    slide_name = row['slide']\n",
    "    class_name = row['label']\n",
    "\n",
    "    # Construct paths using os.path.join\n",
    "    npz_file = os.path.join(features_base_path, class_name, f\"{slide_name}.npz\")\n",
    "    slide_path = os.path.join(slides_base_path, class_name, f\"{slide_name}.tiff\")\n",
    "    output_path = os.path.join(output_base_path, class_name, f\"{slide_name}.png\")\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    # Generate the heatmap\n",
    "    generate_heatmap(npz_file, slide_path, model, output_path, class_names=train_dataset.classes)\n",
    "\n",
    "    # Clean up memory\n",
    "    gc.collect()\n",
    "\n",
    "    # Break after processing the first row (remove this if you want to process all rows)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71a339c-72ad-44d1-9718-500837f76110",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrcnn_tf3_8",
   "language": "python",
   "name": "mrcnn_tf3_8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
